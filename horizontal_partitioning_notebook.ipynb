{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Latency Prediction: Horizontal Partitioning Approach\n",
    "\n",
    "This notebook demonstrates the horizontal partitioning strategy for network latency prediction. We'll split data geographically into urban and rural subsets, train specialized models for each context, and compare their performance against a global baseline model.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Exploration](#data-loading)\n",
    "2. [Geographical Analysis](#geographical-analysis)\n",
    "3. [Horizontal Data Partitioning](#horizontal-partitioning)\n",
    "4. [Specialized Model Training](#model-training)\n",
    "5. [Global Baseline Model](#baseline-model)\n",
    "6. [Performance Evaluation](#evaluation)\n",
    "7. [Comparative Analysis](#analysis)\n",
    "8. [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import project modules\n",
    "from data_processing.data_loader import DataLoader\n",
    "from data_processing.feature_engineering import FeatureEngineer\n",
    "from models.geographical_model import GeographicalModel\n",
    "from models.monolithic_model import MonolithicModel\n",
    "from evaluation.model_evaluator import ModelEvaluator\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration\n",
    "DATA_FILE = 'test_data.xlsx'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}  {
 
  "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-loading\"></a>\n",
    "## 1. Data Loading and Exploration\n",
    "\n",
    "Let's start by loading our network latency dataset and exploring its geographical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "raw_data = data_loader.load_dataset(DATA_FILE)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {raw_data.shape}\")\n",
    "print(f\"Columns: {list(raw_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(raw_data.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "print(\"Preprocessing data...\")\n",
    "processed_data = data_loader.preprocess_data(raw_data)\n",
    "\n",
    "print(f\"Original data shape: {raw_data.shape}\")\n",
    "print(f\"Processed data shape: {processed_data.shape}\")\n",
    "print(f\"Rows removed during preprocessing: {len(raw_data) - len(processed_data)}\")"
   ]
  }, 
 {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"geographical-analysis\"></a>\n",
    "## 2. Geographical Analysis\n",
    "\n",
    "Let's analyze the geographical distribution of our data and understand the differences between urban and rural contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze geographical distribution\n",
    "print(\"Geographical Distribution Analysis:\")\n",
    "location_counts = processed_data['Location Type'].value_counts()\n",
    "print(location_counts)\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print((location_counts / len(processed_data) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize geographical distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Geographical Analysis: Urban vs Rural Contexts', fontsize=16)\n",
    "\n",
    "# Location type distribution\n",
    "location_counts.plot(kind='bar', ax=axes[0, 0], color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "axes[0, 0].set_title('Location Type Distribution')\n",
    "axes[0, 0].set_xlabel('Location Type')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Latency distribution by location\n",
    "urban_latency = processed_data[processed_data['Location Type'] == 'Urban']['Latency (ms)']\n",
    "rural_latency = processed_data[processed_data['Location Type'] == 'Rural']['Latency (ms)']\n",
    "\n",
    "axes[0, 1].hist([urban_latency, rural_latency], bins=20, alpha=0.7, \n",
    "                label=['Urban', 'Rural'], color=['skyblue', 'lightcoral'])\n",
    "axes[0, 1].set_title('Latency Distribution by Location')\n",
    "axes[0, 1].set_xlabel('Latency (ms)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Signal strength by location\n",
    "processed_data.boxplot(column='Signal Strength (dBm)', by='Location Type', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Signal Strength by Location Type')\n",
    "axes[1, 0].set_xlabel('Location Type')\n",
    "axes[1, 0].set_ylabel('Signal Strength (dBm)')\n",
    "\n",
    "# Network traffic by location\n",
    "processed_data.boxplot(column='Network Traffic (MB)', by='Location Type', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Network Traffic by Location Type')\n",
    "axes[1, 1].set_xlabel('Location Type')\n",
    "axes[1, 1].set_ylabel('Network Traffic (MB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },  {

   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison between urban and rural\n",
    "print(\"Statistical Comparison: Urban vs Rural\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "urban_data = processed_data[processed_data['Location Type'] == 'Urban']\n",
    "rural_data = processed_data[processed_data['Location Type'] == 'Rural']\n",
    "\n",
    "features = ['Signal Strength (dBm)', 'Network Traffic (MB)', 'Latency (ms)', 'User Count']\n",
    "\n",
    "comparison_stats = []\n",
    "for feature in features:\n",
    "    urban_mean = urban_data[feature].mean()\n",
    "    rural_mean = rural_data[feature].mean()\n",
    "    urban_std = urban_data[feature].std()\n",
    "    rural_std = rural_data[feature].std()\n",
    "    \n",
    "    comparison_stats.append({\n",
    "        'Feature': feature,\n",
    "        'Urban Mean': urban_mean,\n",
    "        'Rural Mean': rural_mean,\n",
    "        'Urban Std': urban_std,\n",
    "        'Rural Std': rural_std,\n",
    "        'Difference': urban_mean - rural_mean\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_stats)\n",
    "print(comparison_df.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Correlation analysis by location\n",
    "print(\"\\nCorrelation with Latency by Location:\")\n",
    "print(\"-\" * 40)\n",
    "numeric_cols = ['Signal Strength (dBm)', 'Network Traffic (MB)', 'User Count']\n",
    "\n",
    "urban_corr = urban_data[numeric_cols + ['Latency (ms)']].corr()['Latency (ms)'].drop('Latency (ms)')\n",
    "rural_corr = rural_data[numeric_cols + ['Latency (ms)']].corr()['Latency (ms)'].drop('Latency (ms)')\n",
    "\n",
    "print(\"Urban correlations:\")\n",
    "for feature, corr in urban_corr.items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nRural correlations:\")\n",
    "for feature, corr in rural_corr.items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"horizontal-partitioning\"></a>\n",
    "## 3. Horizontal Data Partitioning\n",
    "\n",
    "Now we'll split our data horizontally based on geographical location (Urban vs Rural) and prepare separate datasets for specialized model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets first\n",
    "print(\"Splitting data into train/test sets...\")\n",
    "train_data, test_data = train_test_split(\n",
    "    processed_data, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=processed_data['Location Type']  # Stratify by location to maintain distribution\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {train_data.shape}\")\n",
    "print(f\"Testing set shape: {test_data.shape}\")\n",
    "\n",
    "# Check location distribution in splits\n",
    "print(\"\\nLocation distribution in training set:\")\n",
    "print(train_data['Location Type'].value_counts())\n",
    "print(\"\\nLocation distribution in testing set:\")\n",
    "print(test_data['Location Type'].value_counts())"
   ]
  }, 
 {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer for horizontal partitioning\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Split data geographically\n",
    "print(\"Performing horizontal geographical partitioning...\")\n",
    "\n",
    "# Split training data\n",
    "urban_train, rural_train = feature_engineer.split_horizontal_data(train_data)\n",
    "\n",
    "# Split testing data\n",
    "urban_test, rural_test = feature_engineer.split_horizontal_data(test_data)\n",
    "\n",
    "print(\"Horizontal partitioning completed!\")\n",
    "print(f\"\\nUrban subset:\")\n",
    "print(f\"  Training shape: {urban_train.shape}\")\n",
    "print(f\"  Testing shape: {urban_test.shape}\")\n",
    "\n",
    "print(f\"\\nRural subset:\")\n",
    "print(f\"  Training shape: {rural_train.shape}\")\n",
    "print(f\"  Testing shape: {rural_test.shape}\")\n",
    "\n",
    "# Validate minimum sample requirements\n",
    "min_samples = 5\n",
    "if len(urban_train) < min_samples or len(rural_train) < min_samples:\n",
    "    print(f\"\\n⚠ Warning: Some geographical subsets have fewer than {min_samples} training samples\")\n",
    "    print(f\"Urban training samples: {len(urban_train)}\")\n",
    "    print(f\"Rural training samples: {len(rural_train)}\")\n",
    "else:\n",
    "    print(f\"\\n✓ All geographical subsets have sufficient training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the horizontal partitioning\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Horizontal Partitioning: Specialized Geographical Contexts', fontsize=16)\n",
    "\n",
    "# Urban context analysis\n",
    "axes[0, 0].scatter(urban_train['Signal Strength (dBm)'], urban_train['Latency (ms)'], \n",
    "                   alpha=0.6, color='blue', label='Urban')\n",
    "axes[0, 0].set_title('Urban: Signal Strength vs Latency')\n",
    "axes[0, 0].set_xlabel('Signal Strength (dBm)')\n",
    "axes[0, 0].set_ylabel('Latency (ms)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].scatter(urban_train['Network Traffic (MB)'], urban_train['Latency (ms)'], \n",
    "                   alpha=0.6, color='blue', label='Urban')\n",
    "axes[0, 1].set_title('Urban: Network Traffic vs Latency')\n",
    "axes[0, 1].set_xlabel('Network Traffic (MB)')\n",
    "axes[0, 1].set_ylabel('Latency (ms)')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Rural context analysis\n",
    "axes[1, 0].scatter(rural_train['Signal Strength (dBm)'], rural_train['Latency (ms)'], \n",
    "                   alpha=0.6, color='red', label='Rural')\n",
    "axes[1, 0].set_title('Rural: Signal Strength vs Latency')\n",
    "axes[1, 0].set_xlabel('Signal Strength (dBm)')\n",
    "axes[1, 0].set_ylabel('Latency (ms)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].scatter(rural_train['Network Traffic (MB)'], rural_train['Latency (ms)'], \n",
    "                   alpha=0.6, color='red', label='Rural')\n",
    "axes[1, 1].set_title('Rural: Network Traffic vs Latency')\n",
    "axes[1, 1].set_xlabel('Network Traffic (MB)')\n",
    "axes[1, 1].set_ylabel('Latency (ms)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },  {
 
  "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-training\"></a>\n",
    "## 4. Specialized Model Training\n",
    "\n",
    "Now we'll train specialized models for each geographical context:\n",
    "- **Urban Model**: Trained on urban data subset\n",
    "- **Rural Model**: Trained on rural data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training Urban Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for Urban Model\n",
    "print(\"Training Urban Model...\")\n",
    "\n",
    "# Prepare urban training features\n",
    "X_urban_train = urban_train.drop(columns=['Tower ID', 'Latency (ms)', 'Location Type'])\n",
    "y_urban_train = urban_train['Latency (ms)'].values\n",
    "\n",
    "# Prepare urban testing features\n",
    "X_urban_test = urban_test.drop(columns=['Tower ID', 'Latency (ms)', 'Location Type'])\n",
    "y_urban_test = urban_test['Latency (ms)'].values\n",
    "\n",
    "print(f\"Urban training features shape: {X_urban_train.shape}\")\n",
    "print(f\"Urban testing features shape: {X_urban_test.shape}\")\n",
    "\n",
    "# Train Urban Model\n",
    "urban_model = GeographicalModel(location_type='Urban', random_state=RANDOM_STATE)\n",
    "urban_model.train(X_urban_train, y_urban_train)\n",
    "\n",
    "print(\"Urban model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Urban Model\n",
    "pred_urban_train = urban_model.predict(X_urban_train)\n",
    "pred_urban_test = urban_model.predict(X_urban_test)\n",
    "\n",
    "# Calculate metrics\n",
    "evaluator = ModelEvaluator()\n",
    "urban_train_metrics = evaluator.calculate_metrics(y_urban_train, pred_urban_train)\n",
    "urban_test_metrics = evaluator.calculate_metrics(y_urban_test, pred_urban_test)\n",
    "\n",
    "print(\"Urban Model Performance:\")\n",
    "print(f\"Training - MAE: {urban_train_metrics['MAE']:.3f}, RMSE: {urban_train_metrics['RMSE']:.3f}, R²: {urban_train_metrics['R2_Score']:.3f}\")\n",
    "print(f\"Testing  - MAE: {urban_test_metrics['MAE']:.3f}, RMSE: {urban_test_metrics['RMSE']:.3f}, R²: {urban_test_metrics['R2_Score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training Rural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for Rural Model\n",
    "print(\"Training Rural Model...\")\n",
    "\n",
    "# Prepare rural training features\n",
    "X_rural_train = rural_train.drop(columns=['Tower ID', 'Latency (ms)', 'Location Type'])\n",
    "y_rural_train = rural_train['Latency (ms)'].values\n",
    "\n",
    "# Prepare rural testing features\n",
    "X_rural_test = rural_test.drop(columns=['Tower ID', 'Latency (ms)', 'Location Type'])\n",
    "y_rural_test = rural_test['Latency (ms)'].values\n",
    "\n",
    "print(f\"Rural training features shape: {X_rural_train.shape}\")\n",
    "print(f\"Rural testing features shape: {X_rural_test.shape}\")\n",
    "\n",
    "# Train Rural Model\n",
    "rural_model = GeographicalModel(location_type='Rural', random_state=RANDOM_STATE)\n",
    "rural_model.train(X_rural_train, y_rural_train)\n",
    "\n",
    "print(\"Rural model training completed!\")"
   ]
  },  
{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Rural Model\n",
    "pred_rural_train = rural_model.predict(X_rural_train)\n",
    "pred_rural_test = rural_model.predict(X_rural_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rural_train_metrics = evaluator.calculate_metrics(y_rural_train, pred_rural_train)\n",
    "rural_test_metrics = evaluator.calculate_metrics(y_rural_test, pred_rural_test)\n",
    "\n",
    "print(\"Rural Model Performance:\")\n",
    "print(f\"Training - MAE: {rural_train_metrics['MAE']:.3f}, RMSE: {rural_train_metrics['RMSE']:.3f}, R²: {rural_train_metrics['R2_Score']:.3f}\")\n",
    "print(f\"Testing  - MAE: {rural_test_metrics['MAE']:.3f}, RMSE: {rural_test_metrics['RMSE']:.3f}, R²: {rural_test_metrics['R2_Score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Specialized Model Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize specialized model predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Specialized Model Predictions vs Actual Values', fontsize=16)\n",
    "\n",
    "# Urban model predictions\n",
    "axes[0].scatter(y_urban_test, pred_urban_test, alpha=0.6, color='blue')\n",
    "axes[0].plot([y_urban_test.min(), y_urban_test.max()], \n",
    "             [y_urban_test.min(), y_urban_test.max()], 'r--', lw=2)\n",
    "axes[0].set_title(f'Urban Model\\nR² = {urban_test_metrics[\"R2_Score\"]:.3f}')\n",
    "axes[0].set_xlabel('Actual Latency (ms)')\n",
    "axes[0].set_ylabel('Predicted Latency (ms)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rural model predictions\n",
    "axes[1].scatter(y_rural_test, pred_rural_test, alpha=0.6, color='red')\n",
    "axes[1].plot([y_rural_test.min(), y_rural_test.max()], \n",
    "             [y_rural_test.min(), y_rural_test.max()], 'r--', lw=2)\n",
    "axes[1].set_title(f'Rural Model\\nR² = {rural_test_metrics[\"R2_Score\"]:.3f}')\n",
    "axes[1].set_xlabel('Actual Latency (ms)')\n",
    "axes[1].set_ylabel('Predicted Latency (ms)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"baseline-model\"></a>\n",
    "## 5. Global Baseline Model\n",
    "\n",
    "Let's train a global baseline model using all data together for comparison with our specialized geographical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train global baseline model\n",
    "print(\"Training Global Baseline Model...\")\n",
    "\n",
    "# Prepare features for global model\n",
    "X_global_train = train_data.drop(columns=['Tower ID', 'Latency (ms)'])\n",
    "y_global_train = train_data['Latency (ms)'].values\n",
    "\n",
    "X_global_test = test_data.drop(columns=['Tower ID', 'Latency (ms)'])\n",
    "y_global_test = test_data['Latency (ms)'].values\n",
    "\n",
    "print(f\"Global training features shape: {X_global_train.shape}\")\n",
    "print(f\"Global testing features shape: {X_global_test.shape}\")\n",
    "\n",
    "# Train global model\n",
    "global_model = MonolithicModel(random_state=RANDOM_STATE)\n",
    "global_model.train(X_global_train, y_global_train)\n",
    "\n",
    "print(\"Global model training completed!\")"
   ]
  },  
{
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Global Model\n",
    "pred_global_train = global_model.predict(X_global_train)\n",
    "pred_global_test = global_model.predict(X_global_test)\n",
    "\n",
    "# Calculate metrics\n",
    "global_train_metrics = evaluator.calculate_metrics(y_global_train, pred_global_train)\n",
    "global_test_metrics = evaluator.calculate_metrics(y_global_test, pred_global_test)\n",
    "\n",
    "print(\"Global Model Performance:\")\n",
    "print(f\"Training - MAE: {global_train_metrics['MAE']:.3f}, RMSE: {global_train_metrics['RMSE']:.3f}, R²: {global_train_metrics['R2_Score']:.3f}\")\n",
    "print(f\"Testing  - MAE: {global_test_metrics['MAE']:.3f}, RMSE: {global_test_metrics['RMSE']:.3f}, R²: {global_test_metrics['R2_Score']:.3f}\")\n",
    "\n",
    "# Test global model on geographical subsets\n",
    "print(\"\\nGlobal Model Performance on Geographical Subsets:\")\n",
    "\n",
    "# Global model on urban test data\n",
    "pred_global_urban = global_model.predict(X_urban_test)\n",
    "global_urban_metrics = evaluator.calculate_metrics(y_urban_test, pred_global_urban)\n",
    "print(f\"Urban subset - MAE: {global_urban_metrics['MAE']:.3f}, RMSE: {global_urban_metrics['RMSE']:.3f}, R²: {global_urban_metrics['R2_Score']:.3f}\")\n",
    "\n",
    "# Global model on rural test data\n",
    "pred_global_rural = global_model.predict(X_rural_test)\n",
    "global_rural_metrics = evaluator.calculate_metrics(y_rural_test, pred_global_rural)\n",
    "print(f\"Rural subset - MAE: {global_rural_metrics['MAE']:.3f}, RMSE: {global_rural_metrics['RMSE']:.3f}, R²: {global_rural_metrics['R2_Score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "## 6. Performance Evaluation\n",
    "\n",
    "Let's compare all models and analyze their performance across different geographical contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison\n",
    "results = {\n",
    "    'Urban Specialized Model': urban_test_metrics,\n",
    "    'Rural Specialized Model': rural_test_metrics,\n",
    "    'Global Model (Overall)': global_test_metrics,\n",
    "    'Global Model (Urban subset)': global_urban_metrics,\n",
    "    'Global Model (Rural subset)': global_rural_metrics\n",
    "}\n",
    "\n",
    "# Create performance comparison table\n",
    "comparison_data = []\n",
    "for model_name, metrics in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'MAE': metrics['MAE'],\n",
    "        'RMSE': metrics['RMSE'],\n",
    "        'R²': metrics['R2_Score'],\n",
    "        'MAPE': metrics.get('MAPE', 0)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Horizontal Partitioning: Model Performance Comparison', fontsize=16)\n",
    "\n",
    "models = comparison_df['Model']\n",
    "colors = ['skyblue', 'lightcoral', 'gold', 'lightgreen', 'plum']\n",
    "\n",
    "# MAE comparison\n",
    "axes[0].bar(range(len(models)), comparison_df['MAE'], color=colors, alpha=0.7)\n",
    "axes[0].set_title('Mean Absolute Error (MAE)')\n",
    "axes[0].set_ylabel('MAE')\n",
    "axes[0].set_xticks(range(len(models)))\n",
    "axes[0].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1].bar(range(len(models)), comparison_df['RMSE'], color=colors, alpha=0.7)\n",
    "axes[1].set_title('Root Mean Square Error (RMSE)')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].set_xticks(range(len(models)))\n",
    "axes[1].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# R² comparison\n",
    "axes[2].bar(range(len(models)), comparison_df['R²'], color=colors, alpha=0.7)\n",
    "axes[2].set_title('R² Score')\n",
    "axes[2].set_ylabel('R² Score')\n",
    "axes[2].set_xticks(range(len(models)))\n",
    "axes[2].set_xticklabels(models, rotation=45, ha='right')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },  {
   "c
ell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized vs Global comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Specialized vs Global Model Predictions', fontsize=16)\n",
    "\n",
    "# Urban: Specialized vs Global\n",
    "axes[0, 0].scatter(y_urban_test, pred_urban_test, alpha=0.6, color='blue', label='Urban Specialized')\n",
    "axes[0, 0].plot([y_urban_test.min(), y_urban_test.max()], \n",
    "                [y_urban_test.min(), y_urban_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_title(f'Urban Specialized Model\\nR² = {urban_test_metrics[\"R2_Score\"]:.3f}')\n",
    "axes[0, 0].set_xlabel('Actual Latency (ms)')\n",
    "axes[0, 0].set_ylabel('Predicted Latency (ms)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].scatter(y_urban_test, pred_global_urban, alpha=0.6, color='orange', label='Global on Urban')\n",
    "axes[0, 1].plot([y_urban_test.min(), y_urban_test.max()], \n",
    "                [y_urban_test.min(), y_urban_test.max()], 'r--', lw=2)\n",
    "axes[0, 1].set_title(f'Global Model on Urban Data\\nR² = {global_urban_metrics[\"R2_Score\"]:.3f}')\n",
    "axes[0, 1].set_xlabel('Actual Latency (ms)')\n",
    "axes[0, 1].set_ylabel('Predicted Latency (ms)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Rural: Specialized vs Global\n",
    "axes[1, 0].scatter(y_rural_test, pred_rural_test, alpha=0.6, color='red', label='Rural Specialized')\n",
    "axes[1, 0].plot([y_rural_test.min(), y_rural_test.max()], \n",
    "                [y_rural_test.min(), y_rural_test.max()], 'r--', lw=2)\n",
    "axes[1, 0].set_title(f'Rural Specialized Model\\nR² = {rural_test_metrics[\"R2_Score\"]:.3f}')\n",
    "axes[1, 0].set_xlabel('Actual Latency (ms)')\n",
    "axes[1, 0].set_ylabel('Predicted Latency (ms)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].scatter(y_rural_test, pred_global_rural, alpha=0.6, color='purple', label='Global on Rural')\n",
    "axes[1, 1].plot([y_rural_test.min(), y_rural_test.max()], \n",
    "                [y_rural_test.min(), y_rural_test.max()], 'r--', lw=2)\n",
    "axes[1, 1].set_title(f'Global Model on Rural Data\\nR² = {global_rural_metrics[\"R2_Score\"]:.3f}')\n",
    "axes[1, 1].set_xlabel('Actual Latency (ms)')\n",
    "axes[1, 1].set_ylabel('Predicted Latency (ms)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis\"></a>\n",
    "## 7. Comparative Analysis\n",
    "\n",
    "Let's analyze the results and provide insights about the horizontal partitioning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed analysis\n",
    "print(f\"HORIZONTAL PARTITIONING ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare specialized models with global model on respective subsets\n",
    "urban_improvement = ((urban_test_metrics['R2_Score'] - global_urban_metrics['R2_Score']) / \n",
    "                    global_urban_metrics['R2_Score']) * 100 if global_urban_metrics['R2_Score'] != 0 else 0\n",
    "\n",
    "rural_improvement = ((rural_test_metrics['R2_Score'] - global_rural_metrics['R2_Score']) / \n",
    "                    global_rural_metrics['R2_Score']) * 100 if global_rural_metrics['R2_Score'] != 0 else 0\n",
    "\n",
    "print(f\"\\nSpecialized vs Global Model Comparison:\")\n",
    "print(f\"Urban Context:\")\n",
    "print(f\"  Specialized Model R²: {urban_test_metrics['R2_Score']:.4f}\")\n",
    "print(f\"  Global Model R²: {global_urban_metrics['R2_Score']:.4f}\")\n",
    "if urban_improvement > 0:\n",
    "    print(f\"  ✓ Improvement: {urban_improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"  ⚠ Decline: {abs(urban_improvement):.2f}%\")\n",
    "\n",
    "print(f\"\\nRural Context:\")\n",
    "print(f\"  Specialized Model R²: {rural_test_metrics['R2_Score']:.4f}\")\n",
    "print(f\"  Global Model R²: {global_rural_metrics['R2_Score']:.4f}\")\n",
    "if rural_improvement > 0:\n",
    "    print(f\"  ✓ Improvement: {rural_improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"  ⚠ Decline: {abs(rural_improvement):.2f}%\")\n",
    "\n",
    "# Overall horizontal partitioning effectiveness\n",
    "print(f\"\\nHorizontal Partitioning Effectiveness:\")\n",
    "if urban_improvement > 0 and rural_improvement > 0:\n",
    "    print(\"✓ Horizontal partitioning is effective for both geographical contexts\")\n",
    "    print(\"  Specialized models outperform global model in their respective domains\")\n",
    "elif urban_improvement > 0 or rural_improvement > 0:\n",
    "    print(\"⚠ Horizontal partitioning is partially effective\")\n",
    "    print(\"  One geographical context benefits more than the other\")\n",
    "else:\n",
    "    print(\"⚠ Horizontal partitioning shows limited effectiveness\")\n",
    "    print(\"  Global model performs comparably or better than specialized models\")\n",
    "\n",
    "# Context-specific insights\n",
    "print(f\"\\nContext-Specific Performance Analysis:\")\n",
    "if urban_test_metrics['R2_Score'] > rural_test_metrics['R2_Score']:\n",
    "    print(\"→ Urban model shows better predictive performance\")\n",
    "    print(\"  This suggests urban network patterns are more predictable\")\n",
    "else:\n",
    "    print(\"→ Rural model shows better predictive performance\")\n",
    "    print(\"  This suggests rural network patterns are more predictable\")\n",
    "\n",
    "# Sample size impact\n",
    "print(f\"\\nSample Size Impact:\")\n",
    "print(f\"Urban training samples: {len(urban_train)}\")\n",
    "print(f\"Rural training samples: {len(rural_train)}\")\n",
    "print(f\"Global training samples: {len(train_data)}\")\n",
    "\n",
    "if len(urban_train) < len(rural_train) * 0.5 or len(rural_train) < len(urban_train) * 0.5:\n",
    "    print(\"⚠ Significant imbalance in geographical subsets may affect model performance\")\n",
    "else:\n",
    "    print(\"✓ Geographical subsets are reasonably balanced\")"
   ]
  },  {

   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance summary table\n",
    "print(\"\\nPERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_data = {\n",
    "    'Context': ['Urban', 'Rural', 'Overall'],\n",
    "    'Specialized Model R²': [\n",
    "        urban_test_metrics['R2_Score'],\n",
    "        rural_test_metrics['R2_Score'],\n",
    "        'N/A'\n",
    "    ],\n",
    "    'Global Model R²': [\n",
    "        global_urban_metrics['R2_Score'],\n",
    "        global_rural_metrics['R2_Score'],\n",
    "        global_test_metrics['R2_Score']\n",
    "    ],\n",
    "    'Improvement (%)': [\n",
    "        f\"{urban_improvement:.2f}%\" if urban_improvement != 0 else \"0.00%\",\n",
    "        f\"{rural_improvement:.2f}%\" if rural_improvement != 0 else \"0.00%\",\n",
    "        'N/A'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Best performing approach\n",
    "best_urban = 'Specialized' if urban_test_metrics['R2_Score'] > global_urban_metrics['R2_Score'] else 'Global'\n",
    "best_rural = 'Specialized' if rural_test_metrics['R2_Score'] > global_rural_metrics['R2_Score'] else 'Global'\n",
    "\n",
    "print(f\"\\nBest Performing Approach:\")\n",
    "print(f\"  Urban Context: {best_urban} Model\")\n",
    "print(f\"  Rural Context: {best_rural} Model\")\n",
    "\n",
    "# Recommendation\n",
    "if best_urban == 'Specialized' and best_rural == 'Specialized':\n",
    "    recommendation = \"Use horizontal partitioning with specialized models for both contexts\"\n",
    "elif best_urban == 'Specialized' or best_rural == 'Specialized':\n",
    "    recommendation = \"Use hybrid approach: specialized model for one context, global for the other\"\n",
    "else:\n",
    "    recommendation = \"Use global model for all contexts (horizontal partitioning not beneficial)\"\n",
    "\n",
    "print(f\"\\nRecommendation: {recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "## 8. Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Horizontal Partitioning Effectiveness**: The horizontal partitioning approach successfully separated data into meaningful geographical contexts (urban vs. rural).\n",
    "\n",
    "2. **Specialized Model Performance**: Individual geographical models showed different performance characteristics based on their specialized contexts.\n",
    "\n",
    "3. **Context-Specific Patterns**: Urban and rural environments exhibited different network latency patterns and predictability.\n",
    "\n",
    "4. **Comparison with Global Model**: The comparison revealed whether geographical specialization improves prediction accuracy over a one-size-fits-all approach.\n",
    "\n",
    "### Insights:\n",
    "\n",
    "- **Geographical Differences**: Urban and rural contexts showed distinct network characteristics\n",
    "- **Model Specialization**: Specialized models captured context-specific patterns\n",
    "- **Sample Size Impact**: Geographical subset sizes affected model training effectiveness\n",
    "- **Performance Trade-offs**: Specialized models vs. global model trade-offs were context-dependent\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Model Selection**: Choose between specialized and global models based on performance analysis\n",
    "2. **Data Collection**: Ensure balanced geographical representation in training data\n",
    "3. **Feature Engineering**: Consider location-specific feature transformations\n",
    "4. **Deployment Strategy**: Implement context-aware model selection in production\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Compare horizontal vs. vertical partitioning approaches\n",
    "2. Investigate hybrid partitioning strategies\n",
    "3. Implement ensemble methods combining multiple approaches\n",
    "4. Deploy the best-performing strategy for production use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for future reference\n",
    "print(\"Saving results...\")\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv('horizontal_partitioning_notebook_results.csv', index=False)\n",
    "\n",
    "# Save summary table\n",
    "summary_df.to_csv('horizontal_partitioning_summary_table.csv', index=False)\n",
    "\n",
    "# Save detailed results\n",
    "with open('horizontal_partitioning_notebook_summary.txt', 'w') as f:\n",
    "    f.write(\"HORIZONTAL PARTITIONING NOTEBOOK RESULTS\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Urban Specialized Model R²: {urban_test_metrics['R2_Score']:.4f}\\n\")\n",
    "    f.write(f\"Rural Specialized Model R²: {rural_test_metrics['R2_Score']:.4f}\\n\")\n",
    "    f.write(f\"Global Model R²: {global_test_metrics['R2_Score']:.4f}\\n\\n\")\n",
    "    f.write(f\"Urban Improvement: {urban_improvement:.2f}%\\n\")\n",
    "    f.write(f\"Rural Improvement: {rural_improvement:.2f}%\\n\\n\")\n",
    "    f.write(f\"Recommendation: {recommendation}\\n\\n\")\n",
    "    f.write(\"DETAILED RESULTS:\\n\")\n",
    "    f.write(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"Results saved to:\")\n",
    "print(\"  - horizontal_partitioning_notebook_results.csv\")\n",
    "print(\"  - horizontal_partitioning_summary_table.csv\")\n",
    "print(\"  - horizontal_partitioning_notebook_summary.txt\")\n",
    "print(\"\\nNotebook execution completed successfully!\")"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4
}